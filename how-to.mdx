---
title: "How-To Guides"
description: "How do I ______ with Oumi?"
icon: block-question
---

## <Icon icon="hexagon-nodes" size={32} /> Inference
<AccordionGroup>
<Accordion title="How do I chat with my model?">
    You can use the command `oumi chat` to launch a chatbot powered by your model.
</Accordion>

<Accordion title="How do I prepare data in Oumi's format for inference?">
    x
</Accordion>

<Accordion title="How do I perform inference on a large language model (LLM)?">
    x
</Accordion>

<Accordion title="How do I perform inference on a vision-language model (VLM)?">
    x
</Accordion>

</AccordionGroup>

## <Icon icon="gears" size={32} /> Models
<AccordionGroup>
    <Accordion title="How do I use OpenAI's gpt-oss models?">
    </Accordion>
    
    <Accordion title="How do I use Alibaba's qwen3 models?">
    </Accordion>

    <Accordion title="How do I use DeepSeek's deepseek-r1 models?">
    </Accordion>
</AccordionGroup>

## <Icon icon="wrench" size={32} /> Fine-tuning
<AccordionGroup>
    <Accordion title="How do I prepare my data in Oumi's format for fine-tuning?">
    </Accordion>

    <Accordion title="How do I fine-tune an LLM on labeled data?">
    [Supervised fine-tuning]
    </Accordion>

    <Accordion title="How do I fine-tune a VLM on labeled data?">
    </Accordion>

    <Accordion title="How do I perform parameter-efficient fine-tuning with LoRA?">
    LoRA can be used with different learning objectives such as SFT, DPO, or GRPO
    </Accordion>

    <Accordion title="How do I merge the LoRA weights into the model's weights?">
    </Accordion>

    <Accordion title="How do I fine-tune my model by reinforcement learning (e.g. GRPO)?">
    </Accordion>
    
    <Accordion title="How do I define a reward function for reinforcement learning?">
    </Accordion>

    <Accordion title="How do I fine-tune my model on preference data by DPO or its variants?">
    </Accordion>

    <Accordion title="How do I perform model pre-training with Oumi?">
    x
</Accordion>
</AccordionGroup>

## <Icon icon="scale-balanced" size={32} /> Evaluation
<AccordionGroup>
    <Accordion title="How do I benchmark my model with, e.g., MMLU, HumanEval, or HellaSwag?">
    </Accordion>
    
    <Accordion title="How do I evaluate my model with LLM-as-a-Judge?">
    </Accordion>

    <Accordion title="How do I create a custom judge?">
    </Accordion>
</AccordionGroup>

## <Icon icon="sparkles" size={32} /> Data synthesis
<AccordionGroup>
    <Accordion title="How do I save the responses from a model to a dataset of prompts?">
    </Accordion>

    <Accordion title="How do I synthesize data ...?">
    </Accordion>

    <Accordion title="How do I use synthesized data for inference or fine-tuning?">
    </Accordion>
</AccordionGroup>

## <Icon icon="cloud" size={32} /> Scaling up
<AccordionGroup>
    <Accordion title="How do I use multiple GPUs for inference?">
    </Accordion>

    <Accordion title="How do I use multiple GPUs for training?">
    </Accordion>

    <Accordion title="How do I launch a job via AWS, GCP, Azure, etc.?">
    </Accordion>

    <Accordion title="How do I use a custom compute cluster with Oumi?">
    </Accordion>

    <Accordion title="How do I deploy a model in production?">
    </Accordion>
</AccordionGroup>

## <Icon icon="gauge-max" size={32} /> Optimization
<AccordionGroup>
    <Accordion title="How do I quantize my model?">
    
    </Accordion>

    <Accordion title="How do I used my quantized model for inference?">
    
    </Accordion>

    <Accordion title="How do I distill a larger teacher model into a smaller student one?">
    </Accordion>

    <Accordion title="How do I use specialized kernel libraries such as Unsloth or FlashInfer?">
    </Accordion>

</AccordionGroup>